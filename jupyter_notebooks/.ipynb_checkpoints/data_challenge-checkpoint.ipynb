{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf6c8a-e236-4566-9660-1e448387b2b7",
   "metadata": {},
   "source": [
    "# MoTMo Sensitibity Analysis\n",
    "\n",
    "The main goal of sensitibity analysis is try to find how output variance changes with respect to inputs. In our model, the outputs are the emissions and the mobility choices, and the inputs are each of the scenarios. We transformed the input space as described in the report, and we ended up with thre variable inputs that represent the three categories: investment - $X_I$, policies - $X_P$, and events - $X_E$. These variables are represented by binary strings, and we made a further transform from binary to the unit interval.\n",
    "\n",
    "We can see this model as a function $f(X)=Y$, where the inputs are the scenarios, so $X=(X_I,X_P,X_E)\\in\\mathbb{R}^3$ and the output is a real value, that in our case can be the emissions or the mobility choices. First, we are going to do an analysis emissions, followed by the mobility choices.\n",
    "\n",
    "The idea consists in estimating certain variances that we are going to define later in order to compute some sesitivity indices (there are first and second order sensitivity indices). We write\n",
    "$$Var(Y)=\\sum_{i=1}^dV_i+\\sum_{i<j}^dV_{ij}+\\ldots+V_{1,2, \\ldots,d}$$where\n",
    "$$V_i=Var_{x_i}(E_{X_{\\sim i}}(Y|X))$$where the $X_{\\sim i}$ notation means the set of all variables except $x_i$. One condition to compute these indices is that the input variables $X_i$ are uniformly distributed and mutually independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36fcc15-2655-4b12-b0a4-182fab7c7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "import MoTmo as mo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab567d6-cf0e-4a50-8925-cc2ec8726dff",
   "metadata": {},
   "source": [
    "### Input Space\n",
    "For the moment, we decided to take as input variables each of the categories (investment: $X_I$, policies: $X_P$ and events: $X_E$). In each of these categories there is a set of options that can be either turned ON or OFF, with the condition that on each of the categories a maximum of two options are turned ON. Thus, we can see each of the input variables as all the set of boolean strings of the given length such that they have no more than two ones. For example, for inverstment $(1,0,0)$ simbolizes any sceario that has the option of *Charging infraestructure* turned ON, while the others, *Public transport subsidy* and *Electric vehicle subsidy* are OFF. \n",
    "\n",
    "### Outputs\n",
    "The natural outputs are: total emissions, mobility choices between cars: public transport (`stock_P`), electric cars (`stock_E`), combustion cars (`stock_C`), non-motorized (`stock_N`) and shared vehicles (`stock_S`).\n",
    "\n",
    "For the scope of this report, we did not take each of the options inside the categories as an input variable given that they are not mutually independent (since we cannot have more than two options ON). This is a further research that can be done in order to describe in more detail the model. Therefore, the sensitibity analysis performed here is going to suggest how sensitive the output is given the input variables ($X_I, X_P, X_E$). For example, and as we are going to see later, the analysis suggests that the total emissions output is more susceptible to changes in policies ($X_P$), and that the factors of policies and events ($X_P$ and $X_E$, resp.) when combined are the most influential for the output.\n",
    "\n",
    "A drawback, and as mentioned earlier, is that this analysis does not tell us nor suggests which options inside the categories are the most influential. For example, the options inside the Policies category are *Car weight regulation*, *Bike friendliness* and *Urban combustion restriction*, but with the result given we cannot say much about which of these options are the most \"important\" for the output of the model. Managing to make a sensitibity analysis in the same fashion as we did here for each of these options, not only requires different theoretical framework, but it is more computationally expensive; there are some estimators for when the model is too complex, but given the dependency of these options, we should modify them accordingly. Thus, for the moment, we will focus on the main category inputs, rather than the individual options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df72b63c-bb2e-4750-abde-f818e4f1c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global variables\n",
    "num_options_per_category = {\n",
    "    'investment' : 3,\n",
    "    'policy' : 3,\n",
    "    'event' : 4\n",
    "}\n",
    "\n",
    "output_vars = ['stock_C','stock_E','stock_N','stock_P','stock_S','total_emissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8358a8dd-afe4-4d72-b240-9dfae06e3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('total_sums_all_variables.csv',index_col=0)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d330b8-e28b-4af2-9446-ba41cc05dd3e",
   "metadata": {},
   "source": [
    "## First-order indices\n",
    "This index is given by $$S_i= \\frac{V_i}{Var(Y)}$$where $V_i=Var_{x_i}(E_{X_{\\sim i}}(Y|X))$. Notice that this form gives us a direct (possible) interpretation: \"it is the fractional reduction in the variance of $Y$ which would be obtained on average if $X$ could be fixed\".\n",
    "\n",
    "In other words, the expected value $E_{X_{\\sim i}}(Y|X)$ computes the mean of all inputs while fixing $X_i$, so the following function `get_input_fix_one` gives us all the input space resulting of fixing an input (`boolean_tuple`) of certain category (can take values 0, 1 or 2, representing investment, policies or events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d814136-dc8d-48da-918e-45b526470f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fix_one(boolean_tuple, category):\n",
    "    if category == 2 and len(boolean_tuple) !=4:\n",
    "        print(\"ERROR: the boolean input does not match Event length, which is 4 (for example, (0,1,0,0)!\")\n",
    "    elif (category ==0 or category ==1) and len(boolean_tuple)!=3:\n",
    "        print(\"ERROR: the boolean input length does not match the category. It must be of length 3 (for example, (1,0,0))\")\n",
    "    else:\n",
    "        input_space = mo.generate_input_space_bool(num_options_per_category)\n",
    "        reduced_input = [x for x in input_space if x[category]== boolean_tuple]\n",
    "        return reduced_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fdb289-30cb-4edf-a9e8-cf3158b42b9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 0, 1), (0, 0, 0), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 0), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 0, 0), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 0, 0), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (0, 0, 0), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 0), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (0, 0, 0), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (0, 0, 0), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 0), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 0, 0), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 0, 0), (1, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (0, 0, 1), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 0, 1), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 0, 1), (1, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (0, 1, 0), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 1, 0), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 1, 0), (1, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (0, 1, 1), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (0, 1, 1), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (0, 1, 1), (1, 1, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (1, 0, 0), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (1, 0, 0), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (1, 0, 0), (1, 1, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (1, 0, 1), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (1, 0, 1), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (1, 0, 1), (1, 1, 0, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 0, 0, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 0, 0, 1)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 0, 1, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 0, 1, 1)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 1, 0, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 1, 0, 1)),\n",
       " ((1, 0, 1), (1, 1, 0), (0, 1, 1, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (1, 0, 0, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (1, 0, 0, 1)),\n",
       " ((1, 0, 1), (1, 1, 0), (1, 0, 1, 0)),\n",
       " ((1, 0, 1), (1, 1, 0), (1, 1, 0, 0))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment the following line to see an example\n",
    "# get_input_fix_one(boolean_tuple=(1,0,1), category=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336185e-c20f-40a8-9b4a-8c17e6b59455",
   "metadata": {},
   "source": [
    "The following function computes the variances of the means of the given category and output variable. `sum_df` is the dataframe that contais the sum of all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dcad5d5d-7d94-40d5-b811-dfa4ef983b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance_fixed_xi(category,output_variable, sum_df):\n",
    "    # computes V_xi of the desired output variable\n",
    "    expectations = []\n",
    "    if category == 0 or category == 1:\n",
    "        num_options = 3\n",
    "    elif category == 2:\n",
    "        num_options = 4\n",
    "    input_bool_category = mo.valid_scenarios_for_category(num_options)\n",
    "    for input_cat in input_bool_category:\n",
    "        reduced_boolean_input = get_input_fix_one(input_cat,category)\n",
    "        mask = [mo.get_scenario_string(x) for x in reduced_boolean_input]\n",
    "        temp_df = sum_df[[output_variable]].loc[mask]\n",
    "        expected_xi = temp_df[output_variable].mean()\n",
    "        expectations.append(expected_xi)\n",
    "    var_xi = np.var(expectations)\n",
    "    return var_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf2cf74f-f999-4199-b1c4-4100a7e884f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5554685331202.368"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example for variable of mobility choice of combustion cars, and policies category (1)\n",
    "get_variance_fixed_xi(category=1,output_variable=\"stock_C\", sum_df=df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffbdc0-d56f-499c-9f6f-9494de222bae",
   "metadata": {},
   "source": [
    "With the above functions, we can comput the $V_i$s. Remember that the 1st order indices are given by $$S_i= \\frac{V_i}{Var(Y)}$$Thus, the following function computes the indices of all input factors (variables) and stores it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8170c9cb-9bad-4186-b480-7f52d7fbec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_indices(sum_df, output_vars=output_vars):\n",
    "    index_dict = {\"S_I\":[],\"S_P\":[],\"S_E\":[]}\n",
    "    sobol_names_dict = {\"S_I\":0,\"S_P\":1,\"S_E\":2}\n",
    "    for out_var in output_vars:\n",
    "        var_Y = sum_df[out_var].var()\n",
    "        ind_list = []\n",
    "        for S,i in sobol_names_dict.items():\n",
    "            v_xi = get_variance_fixed_xi(i,out_var,sum_df)\n",
    "            S_i = v_xi / var_Y\n",
    "            ind_list.append(S_i)\n",
    "            index_dict[S].append(S_i)\n",
    "    df = pd.DataFrame.from_dict(index_dict, orient='index',columns=output_vars)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "025e0975-f477-4d8a-a916-30faa2435ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_C</th>\n",
       "      <th>stock_E</th>\n",
       "      <th>stock_N</th>\n",
       "      <th>stock_P</th>\n",
       "      <th>stock_S</th>\n",
       "      <th>total_emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S_I</th>\n",
       "      <td>0.144434</td>\n",
       "      <td>0.487024</td>\n",
       "      <td>0.514822</td>\n",
       "      <td>0.534556</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_P</th>\n",
       "      <td>0.426486</td>\n",
       "      <td>0.150791</td>\n",
       "      <td>0.380571</td>\n",
       "      <td>0.160698</td>\n",
       "      <td>0.229341</td>\n",
       "      <td>0.939900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_E</th>\n",
       "      <td>0.411576</td>\n",
       "      <td>0.280636</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.288213</td>\n",
       "      <td>0.538039</td>\n",
       "      <td>0.042712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock_C   stock_E   stock_N   stock_P   stock_S  total_emissions\n",
       "S_I  0.144434  0.487024  0.514822  0.534556  0.058319         0.005789\n",
       "S_P  0.426486  0.150791  0.380571  0.160698  0.229341         0.939900\n",
       "S_E  0.411576  0.280636  0.089221  0.288213  0.538039         0.042712"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_Si = first_order_indices(sum_df=df2)\n",
    "first_Si"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888cadc6-c513-496f-8314-cf01014a7e2f",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "Refer to the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0fa285-ca95-460d-b3b8-f6d1564eebf6",
   "metadata": {},
   "source": [
    "## Second-order indices\n",
    "The second-order indices measure the interaction of pairs of inputs:\n",
    "$$S_{ij}=\\frac{V_{ij}}{Var(Y)}$$where \n",
    "$$V_{ij}=Var_{X_{ij}}(E_{X_{\\sim ij}}(Y|X_i,X_j))-V_i-V_j$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa67edf5-1658-4e03-acc9-952ccb84b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fix_two(boolean_tuples, categories):\n",
    "    # 'boolean_input' is a pair of tuples (one for each category)\n",
    "    # An example, ((1,0,0),(0,1,0)) for the investment and policies categ.\n",
    "    # It gives us the input space of fixing inputs of 2 categories.\n",
    "    reduced_space1 = get_input_fix_one(boolean_tuples[0],categories[0])\n",
    "    reduced_space2 = [x for x in reduced_space1 if x[categories[1]]== boolean_tuples[1]]\n",
    "    return reduced_space2\n",
    "\n",
    "def get_all_pairs_two_categ(cat1,cat2):\n",
    "    # gives us all the combinations of boolean strigns of two categories.\n",
    "    if cat2<2:\n",
    "        num_ops_dict={0:3,1:3}\n",
    "    else:\n",
    "        num_ops_dict={0:3,1:4}\n",
    "    all_pairs_categ = mo.generate_input_space_bool(num_ops_dict)\n",
    "    return all_pairs_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78b76dcc-2769-4c4e-bb13-86518219209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 0, 0), (0, 0, 0), (0, 0, 0, 0)),\n",
       " ((1, 0, 0), (0, 0, 0), (0, 0, 0, 1)),\n",
       " ((1, 0, 0), (0, 0, 0), (0, 0, 1, 0)),\n",
       " ((1, 0, 0), (0, 0, 0), (0, 0, 1, 1)),\n",
       " ((1, 0, 0), (0, 0, 0), (0, 1, 0, 0)),\n",
       " ((1, 0, 0), (0, 0, 0), (0, 1, 0, 1)),\n",
       " ((1, 0, 0), (0, 0, 0), (0, 1, 1, 0)),\n",
       " ((1, 0, 0), (0, 0, 0), (1, 0, 0, 0)),\n",
       " ((1, 0, 0), (0, 0, 0), (1, 0, 0, 1)),\n",
       " ((1, 0, 0), (0, 0, 0), (1, 0, 1, 0)),\n",
       " ((1, 0, 0), (0, 0, 0), (1, 1, 0, 0))]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of an input on the categories of Investment (0) and Policies (1)\n",
    "get_input_fix_two(boolean_tuples=((1,0,0),(0,0,0)), categories=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9e70177-5cdb-4704-a14e-92fe862bcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Exp_fixed_ij(sum_df, output_variable, cat_tuple=(0,1)):\n",
    "    bool_cat_tuple=get_all_pairs_two_categ(cat_tuple[0],cat_tuple[1])\n",
    "    expectations_list=[]\n",
    "    for boolean_input in bool_cat_tuple:\n",
    "        reduced_input = get_input_fix_two(boolean_input,cat_tuple)\n",
    "        mask = [mo.get_scenario_string(x) for x in reduced_input]\n",
    "        temp_df = sum_df[[output_variable]].loc[mask]\n",
    "        expected_xij = temp_df[output_variable].mean()\n",
    "        expectations_list.append(expected_xij)\n",
    "    variance = np.var(expectations_list) # variance of the given variable/category\n",
    "    return expectations_list,variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "813a8bf4-5bb3-4e48-bf22-d62591d5e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_Var_fixed_ij(sum_df,cat_tuple, output_variables = output_vars):\n",
    "    output_dict={}\n",
    "    for output_var in output_variables:\n",
    "        variance_out = get_Exp_fixed_ij(sum_df, output_var, cat_tuple)[1]\n",
    "        output_dict[output_var] = variance_out\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9f8d584-778b-452c-a89b-468098f05eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_indices(sum_df,output_vars = output_vars):\n",
    "    categories = [\"I\", \"P\", \"E\"]\n",
    "    cat_pairs = list(itertools.combinations(categories, 2))\n",
    "    cat_tuples = list(itertools.combinations(range(3), 2))\n",
    "    cat_dict = dict(zip(cat_pairs,cat_tuples))\n",
    "    second_ind_dict={}\n",
    "    var_Y = list(sum_df.var())\n",
    "    for cat_pair,cat_tuple in cat_dict.items():\n",
    "        v_i = [get_variance_fixed_xi(cat_tuple[0],x, sum_df) for x in output_vars]\n",
    "        v_j = [get_variance_fixed_xi(cat_tuple[1],x, sum_df) for x in output_vars]\n",
    "        var_cat = list(get_all_Var_fixed_ij(sum_df,cat_tuple).values())\n",
    "        np_S_ij = (np.array(var_cat)-np.array(v_i)-np.array(v_j))/np.array(var_Y)\n",
    "        var_cat = list(np_S_ij)\n",
    "        second_ind_dict[cat_pair]=var_cat\n",
    "    second_ind_dict = pd.DataFrame.from_dict(second_ind_dict, orient='index',columns=output_vars)\n",
    "    return second_ind_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "000bdfec-4365-4314-a49c-e0baa3f0b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_C</th>\n",
       "      <th>stock_E</th>\n",
       "      <th>stock_N</th>\n",
       "      <th>stock_P</th>\n",
       "      <th>stock_S</th>\n",
       "      <th>total_emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(I, P)</th>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.035216</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.023244</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(I, E)</th>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.037781</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(P, E)</th>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>0.007984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_C   stock_E   stock_N   stock_P   stock_S  total_emissions\n",
       "(I, P)  0.000557  0.035216  0.000989  0.003023  0.023244         0.000508\n",
       "(I, E)  0.006729  0.037781  0.002485  0.004842  0.012958         0.001033\n",
       "(P, E)  0.007902  0.004284  0.009361  0.006122  0.084962         0.007984"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_Sij = second_order_indices(df2)\n",
    "second_Sij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd6da2-38ff-4ead-9ba2-83642f8fd307",
   "metadata": {},
   "source": [
    "## Total-order index\n",
    "The total-order indev $S_{T_i}$, gives us a further interpretation of the interactions. It is given by\n",
    "\n",
    "$$S_{T_i}=1-\\frac{Var_{X_{\\sim i}}(E_{X_{i}}(Y|X_{\\sim i}))}{Var(Y)}=\\frac{E_{X_{\\sim i}}(Var_{X_{i}}(Y|X_{\\sim i}))}{Var(Y)}$$\n",
    "\n",
    "This equation computes the variance of the mean of all the terms of any order that do not include factor $X_i$. Therefore, it quantifies the *total effect* of the factor $X_i$ by measuring  all variance caused by its interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7df86ae-cf42-4e8c-aa57-45e564c7f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_input_fix_two!!\n",
    "def exp_but_xi(sum_df, category, output_var):\n",
    "    categories = list(range(3))\n",
    "    fixed_cats = [x for x in categories if x != category]\n",
    "    fixed_bools_tuples = get_all_pairs_two_categ(fixed_cats[0],fixed_cats[1])\n",
    "    # bool_cat_tuple=get_all_pairs_two_categ(cat_tuple[0],cat_tuple[1])\n",
    "    expectations_list=[]\n",
    "    for boolean_tuples in fixed_bools_tuples:\n",
    "        reduced_input = get_input_fix_two(boolean_tuples,fixed_cats)\n",
    "        mask = [mo.get_scenario_string(x) for x in reduced_input]\n",
    "        temp_df = sum_df[[output_var]].loc[mask]\n",
    "        expected_xij = temp_df[output_var].mean()\n",
    "        expectations_list.append(expected_xij)\n",
    "    variance = np.var(expectations_list) # variance of the given variable/category\n",
    "    return variance,expectations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3584ccb7-62c5-4060-b625-940d0dc55e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_order_indices_xi(sum_df, output_vars=output_vars):\n",
    "    cat_dict = {\"ST_I\":0, \"ST_P\":1, \"ST_E\":2}\n",
    "    # total_index_dict = {}\n",
    "    total_index_list = []\n",
    "    variance_list = []\n",
    "    for out_var in output_vars:\n",
    "        var_Y = sum_df[out_var].var()\n",
    "        variance_lst = [exp_but_xi(sum_df, category, out_var)[0]/var_Y for category in range(3)]\n",
    "        S_Ti = [1 - v for v in variance_lst]\n",
    "        total_index_list.append(S_Ti)\n",
    "    total_index_list = [[item[i] for item in total_index_list] for i in range(3)]\n",
    "    total_index_dict = dict(zip(list(cat_dict.keys()),total_index_list))\n",
    "    # df = pd.DataFrame.from_dict(total_index_dict, orient='index',columns=output_vars)\n",
    "    return total_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "78906474-0df1-4b3f-b698-f391ec3746a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_C</th>\n",
       "      <th>stock_E</th>\n",
       "      <th>stock_N</th>\n",
       "      <th>stock_P</th>\n",
       "      <th>stock_S</th>\n",
       "      <th>total_emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ST_I</th>\n",
       "      <td>0.154036</td>\n",
       "      <td>0.564289</td>\n",
       "      <td>0.520846</td>\n",
       "      <td>0.544966</td>\n",
       "      <td>0.147658</td>\n",
       "      <td>0.009404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST_P</th>\n",
       "      <td>0.437261</td>\n",
       "      <td>0.194559</td>\n",
       "      <td>0.393472</td>\n",
       "      <td>0.172389</td>\n",
       "      <td>0.390685</td>\n",
       "      <td>0.950466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST_E</th>\n",
       "      <td>0.428523</td>\n",
       "      <td>0.326969</td>\n",
       "      <td>0.103618</td>\n",
       "      <td>0.301723</td>\n",
       "      <td>0.689096</td>\n",
       "      <td>0.053803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock_C   stock_E   stock_N   stock_P   stock_S  total_emissions\n",
       "ST_I  0.154036  0.564289  0.520846  0.544966  0.147658         0.009404\n",
       "ST_P  0.437261  0.194559  0.393472  0.172389  0.390685         0.950466\n",
       "ST_E  0.428523  0.326969  0.103618  0.301723  0.689096         0.053803"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp_list = total_order_indices_xi(sum_df=df2)\n",
    "total_index_dct = total_order_indices_xi(sum_df=df2)\n",
    "total_ST = pd.DataFrame.from_dict(temp_dict, orient='index',columns=output_vars)\n",
    "total_ST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
